name: Create Infrastructure and Deploy Application

on:
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  TF_STATE_BUCKET_PREFIX: "hrgoat-tfstate-do-not-delete"
  TF_STATE_KEY: "terraform/state/prod/terraform.tfstate"
  PROJECT_NAME: "hrgoat"
  DB_PASSWORD: "hrportaladmin123"

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    
    outputs:
      app_instance_id: ${{ steps.terraform_outputs.outputs.app_instance_id }}
      rds_endpoint: ${{ steps.terraform_outputs.outputs.rds_endpoint }}
      ecr_repository_name: ${{ steps.terraform_outputs.outputs.ecr_repository_name }}
      tf_state_bucket: ${{ steps.create_bucket.outputs.bucket_name }}
      alb_dns_name: ${{ steps.terraform_outputs.outputs.alb_dns_name }}
      app_alb_url: ${{ steps.terraform_outputs.outputs.app_alb_url }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: "us-east-1"

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.0.0

    - name: Create unique S3 bucket name for Terraform state
      id: create_bucket
      run: |
        # Generate unique bucket name with epoch timestamp
        TIMESTAMP=$(date +%s)
        BUCKET_NAME="${{ env.TF_STATE_BUCKET_PREFIX }}-${TIMESTAMP}"
        echo "bucket_name=${BUCKET_NAME}" >> $GITHUB_OUTPUT
        echo "Using bucket name: ${BUCKET_NAME}"

    - name: Create S3 bucket for Terraform state if it doesn't exist
      run: |
        BUCKET_NAME="${{ steps.create_bucket.outputs.bucket_name }}"
        
        aws s3api head-bucket --bucket ${BUCKET_NAME} 2>/dev/null || \
        aws s3api create-bucket --bucket ${BUCKET_NAME} --region ${{ env.AWS_REGION }}
        
        # Enable versioning
        aws s3api put-bucket-versioning --bucket ${BUCKET_NAME} --versioning-configuration Status=Enabled
        
        # Store bucket name in a file that will be stored in S3 for reference by destroy workflow
        echo "BUCKET_NAME=${BUCKET_NAME}" > bucket-name.txt
        aws s3 cp bucket-name.txt s3://${BUCKET_NAME}/bucket-name.txt

    - name: Terraform Init
      run: |
        cd terraform
        terraform init \
          -backend-config="bucket=${{ steps.create_bucket.outputs.bucket_name }}" \
          -backend-config="key=${{ env.TF_STATE_KEY }}" \
          -backend-config="region=${{ env.AWS_REGION }}"

    - name: Terraform Plan
      run: |
        cd terraform
        terraform plan -var="project_name=${{ env.PROJECT_NAME }}" -var="db_password=${{ env.DB_PASSWORD }}" -out=tfplan

    - name: Terraform Apply
      run: |
        cd terraform
        terraform apply -auto-approve tfplan

    - name: Export Terraform Outputs
      id: terraform_outputs
      run: |
        cd terraform
        
        # Display all available outputs for debugging
        echo "All Terraform outputs:"
        terraform output || echo "No outputs found"
        
        # Check if core resources were created by querying AWS directly
        echo "Checking for resources created by Terraform..."
        
        # 1. Get the latest EC2 instance by tag and creation time, excluding terminated instances
        echo "Finding the latest app instance..."
        APP_INSTANCE_ID=$(aws ec2 describe-instances \
          --filters \
            "Name=tag:Name,Values=${{ env.PROJECT_NAME }}-app-instance" \
            "Name=instance-state-name,Values=pending,running" \
          --query "Reservations[*].Instances[*].[InstanceId,LaunchTime]" \
          --output text | sort -k2 -r | head -n1 | awk '{print $1}')
        
        # If not found with primary tag, try project tag
        if [ "$APP_INSTANCE_ID" == "None" ] || [ -z "$APP_INSTANCE_ID" ]; then
          echo "Warning: Could not find app instance with tag Name=${{ env.PROJECT_NAME }}-app-instance"
          # Try to fallback to any instance with our project tag, still filtering for non-terminated
          APP_INSTANCE_ID=$(aws ec2 describe-instances \
            --filters \
              "Name=tag-key,Values=Project" \
              "Name=tag-value,Values=${{ env.PROJECT_NAME }}" \
              "Name=instance-state-name,Values=pending,running" \
            --query "Reservations[*].Instances[*].[InstanceId,LaunchTime]" \
            --output text | sort -k2 -r | head -n1 | awk '{print $1}')
        fi
        
        # Verify the instance is in a valid state
        if [ -n "$APP_INSTANCE_ID" ]; then
          INSTANCE_STATE=$(aws ec2 describe-instances \
            --instance-ids "$APP_INSTANCE_ID" \
            --query "Reservations[0].Instances[0].State.Name" \
            --output text)
          echo "Found EC2 instance ID: $APP_INSTANCE_ID (State: $INSTANCE_STATE)"
        else
          echo "Warning: Could not find any running or pending app instances"
        fi
        
        # 2. Get RDS instance by tag/identifier
        RDS_ENDPOINT=$(aws rds describe-db-instances --db-instance-identifier "${{ env.PROJECT_NAME }}-db" --query "DBInstances[0].Endpoint.Address" --output text 2>/dev/null)
        if [ "$RDS_ENDPOINT" == "None" ] || [ -z "$RDS_ENDPOINT" ]; then
          echo "Warning: Could not find RDS instance with identifier ${{ env.PROJECT_NAME }}-db"
          # Look for any instance with similar name
          RDS_ENDPOINT=$(aws rds describe-db-instances --query "DBInstances[?starts_with(DBInstanceIdentifier, '${{ env.PROJECT_NAME }}')].Endpoint.Address" --output text | head -1)
        fi
        RDS_PORT=$(aws rds describe-db-instances --db-instance-identifier "${{ env.PROJECT_NAME }}-db" --query "DBInstances[0].Endpoint.Port" --output text 2>/dev/null || echo "3306")
        RDS_HOST="${RDS_ENDPOINT}:${RDS_PORT}"
        echo "Found RDS endpoint: $RDS_HOST"
        
        # 3. Check ECR repository
        # We're already using a hardcoded repo name, so this is less critical
        ECR_REPOSITORY_NAME="${{ env.PROJECT_NAME }}-app-repository"
        echo "Using ECR repository: $ECR_REPOSITORY_NAME"
        
        # 4. Check ALB
        ALB_DNS_NAME=$(aws elbv2 describe-load-balancers --names "${{ env.PROJECT_NAME }}-alb" --query "LoadBalancers[0].DNSName" --output text 2>/dev/null)
        if [ "$ALB_DNS_NAME" == "None" ] || [ -z "$ALB_DNS_NAME" ]; then
          echo "Warning: Could not find ALB with name ${{ env.PROJECT_NAME }}-alb"
        fi
        APP_ALB_URL="http://${ALB_DNS_NAME}"
        echo "ALB DNS Name: $ALB_DNS_NAME"
        echo "ALB URL: $APP_ALB_URL"
        
        # Set outputs directly in GitHub's format
        echo "app_instance_id=$APP_INSTANCE_ID" >> $GITHUB_OUTPUT
        echo "rds_endpoint=$RDS_HOST" >> $GITHUB_OUTPUT
        echo "ecr_repository_name=$ECR_REPOSITORY_NAME" >> $GITHUB_OUTPUT
        echo "alb_dns_name=$ALB_DNS_NAME" >> $GITHUB_OUTPUT
        echo "app_alb_url=$APP_ALB_URL" >> $GITHUB_OUTPUT

    - name: Verify Terraform Outputs
      run: |
        echo "Terraform outputs set for next job:"
        echo "APP_INSTANCE_ID = ${{ steps.terraform_outputs.outputs.app_instance_id }}"
        echo "RDS_ENDPOINT = ${{ steps.terraform_outputs.outputs.rds_endpoint }}"
        echo "ECR_REPOSITORY_NAME = ${{ steps.terraform_outputs.outputs.ecr_repository_name }}"
        echo "ALB_DNS_NAME = ${{ steps.terraform_outputs.outputs.alb_dns_name }}"
        echo "APP_ALB_URL = ${{ steps.terraform_outputs.outputs.app_alb_url }}"

  build-and-deploy:
    name: 'Build and Deploy Application'
    needs: terraform
    runs-on: ubuntu-latest
    # Always run this job when terraform completes, as the outputs issue should be fixed now

    env:
      APP_INSTANCE_ID: ${{ needs.terraform.outputs.app_instance_id }}
      RDS_HOST: ${{ needs.terraform.outputs.rds_endpoint }}
      ECR_REPOSITORY_NAME: ${{ needs.terraform.outputs.ecr_repository_name }}
      RDS_USER: admin
      RDS_PASSWORD: hrportaladmin123
      RDS_DATABASE: hrportal
      TF_STATE_BUCKET: ${{ needs.terraform.outputs.tf_state_bucket }}
      ALB_DNS_NAME: ${{ needs.terraform.outputs.alb_dns_name }}
      APP_ALB_URL: ${{ needs.terraform.outputs.app_alb_url }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Debug environment variables
      run: |
        echo "ECR Registry: ${{ steps.login-ecr.outputs.registry }}"
        echo "ECR Repository Name: ${{ env.ECR_REPOSITORY_NAME }}"
        if [ -z "${{ env.ECR_REPOSITORY_NAME }}" ]; then
          echo "::error::ECR_REPOSITORY_NAME is empty!"
          exit 1
        fi

    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'

    - name: Build frontend
      run: |
        # Install dependencies with legacy-peer-deps to handle React 19 compatibility
        npm ci --legacy-peer-deps

        # Build frontend to create dist directory
        echo "Building frontend..."
        npm run build
        
        # Verify dist directory was created
        if [ ! -d "./dist" ]; then
          echo "::error::Frontend build failed, dist directory not created"
          exit 1
        fi
        echo "Frontend build successful!"

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
      run: |
        # Construct the full ECR repository URL using the registry from login step
        FULL_ECR_REPOSITORY="${ECR_REGISTRY}/${{ env.ECR_REPOSITORY_NAME }}"
        echo "Full ECR Repository URL: ${FULL_ECR_REPOSITORY}"
        
        # Build a docker container and push it to ECR
        docker build -t ${FULL_ECR_REPOSITORY}:${{ github.sha }} .
        docker push ${FULL_ECR_REPOSITORY}:${{ github.sha }}
        docker tag ${FULL_ECR_REPOSITORY}:${{ github.sha }} ${FULL_ECR_REPOSITORY}:latest
        docker push ${FULL_ECR_REPOSITORY}:latest
        echo "image=${FULL_ECR_REPOSITORY}:${{ github.sha }}" >> $GITHUB_OUTPUT

    - name: Verify EC2 Instance State
      run: |
        MAX_RETRIES=20  # Maximum attempts (increased from 12)
        INSTANCE_ID="${{ env.APP_INSTANCE_ID }}"  # Instance ID
        REGION="${{ env.AWS_REGION }}"  # AWS region
        COUNT=0
        
        if [ -z "$INSTANCE_ID" ]; then
          echo "::error::No valid EC2 instance ID found. Cannot continue verification."
          exit 1
        fi
        
        echo "Verifying state of EC2 instance: $INSTANCE_ID"

        until [ "$INSTANCE_STATE" == "running" ] || [ "$COUNT" -ge "$MAX_RETRIES" ]; do
            INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --region "$REGION" --query "Reservations[0].Instances[0].State.Name" --output text)

            if [ "$INSTANCE_STATE" == "running" ]; then
                echo "✅ EC2 instance $INSTANCE_ID is now in a running state."
                
                # Check if SSM agent is ready by attempting a simple SSM command
                echo "Checking if SSM agent is ready..."
                if aws ssm describe-instance-information --filters "Key=InstanceIds,Values=$INSTANCE_ID" --query "InstanceInformationList[0].PingStatus" --output text | grep -q "Online"; then
                  echo "✅ SSM agent is online and ready."
                else
                  echo "⚠️ SSM agent is not yet reporting as online. Waiting for it to initialize..."
                  # Wait a bit longer for SSM agent to initialize
                  sleep 30
                fi
                break
            fi

            COUNT=$((COUNT+1))
            echo "⏳ Attempt $COUNT/$MAX_RETRIES: EC2 instance $INSTANCE_ID is in '$INSTANCE_STATE' state. Waiting..."
            sleep 15  # Increased wait time between checks
        done

        # One final check after all retries
        INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --region "$REGION" --query "Reservations[0].Instances[0].State.Name" --output text)
        if [ "$INSTANCE_STATE" != "running" ]; then
          echo "::error::EC2 instance $INSTANCE_ID failed to reach running state after $MAX_RETRIES attempts. Current state: $INSTANCE_STATE"
          exit 1
        fi
        
        # Verify the instance has SSM agent properly configured
        echo "Verifying SSM agent on instance $INSTANCE_ID..."
        SSM_STATUS=$(aws ssm describe-instance-information --filters "Key=InstanceIds,Values=$INSTANCE_ID" --query "InstanceInformationList[0].PingStatus" --output text || echo "Unknown")
        
        if [ "$SSM_STATUS" != "Online" ]; then
          echo "::warning::SSM agent on instance $INSTANCE_ID is not reporting as online (status: $SSM_STATUS). Deployment may fail."
          # Don't exit with error, as sometimes SSM can still work even if not reporting online yet
          # Instead, add a delay to give it more time
          echo "Waiting additional time for SSM agent to initialize..."
          sleep 60
        else
          echo "✅ SSM agent is online and ready to receive commands."
        fi

    - name: Deploy to EC2 via SSM
      run: |
        # Verify we have the required values
        echo "Checking essential parameters:"
        echo "APP_INSTANCE_ID: ${{ env.APP_INSTANCE_ID }}"
        echo "RDS_HOST: ${{ env.RDS_HOST }}"
        
        # Exit if essential parameters are missing
        if [ -z "${{ env.APP_INSTANCE_ID }}" ]; then
          echo "::error::APP_INSTANCE_ID is empty! Cannot continue deployment."
          exit 1
        fi
        
        # Extract RDS hostname from endpoint if available
        DB_HOST=""
        if [ -n "${{ env.RDS_HOST }}" ]; then
          DB_HOST=$(echo "${{ env.RDS_HOST }}" | cut -d: -f1)
        fi
        
        # Print all environment variables
        echo "Environment variables:"
        echo "APP_INSTANCE_ID: ${{ env.APP_INSTANCE_ID }}"
        echo "RDS_HOST: ${{ env.RDS_HOST }}"
        echo "ECR_REPOSITORY_NAME: ${{ env.ECR_REPOSITORY_NAME }}"
        echo "RDS_USER: ${{ env.RDS_USER }}"
        echo "RDS_PASSWORD: ${{ env.RDS_PASSWORD }}"
        
        # Create commands JSON string
        COMMANDS_JSON='["docker stop hrportal || true", "docker rm hrportal || true", "aws ecr get-login-password --region '"${{ env.AWS_REGION }}"' | docker login --username AWS --password-stdin '"${{ steps.login-ecr.outputs.registry }}"'", "docker pull '"${{ steps.build-image.outputs.image }}"'", "docker run -d --name hrportal -p 80:80 -p 5001:5001 --network-alias=nomdservice --add-host=metadata.ec2.internal:127.0.0.1 --add-host=169.254.169.254:127.0.0.1 -e DB_HOST=\"'"$DB_HOST"'\" -e DB_USER=\"'"${{ env.RDS_USER }}"'\" -e DB_PASSWORD=\"'"${{ env.RDS_PASSWORD }}"'\" -e DB_NAME=\"'"${{ env.RDS_DATABASE }}"'\" -e FRONTEND_PORT=\"80\" -e BACKEND_PORT=\"5001\" --privileged -e VITE_BASE_URL=\"http://localhost\" '"${{ steps.build-image.outputs.image }}"'", "docker ps | grep hrportal"]'
        
        echo "Using commands: $COMMANDS_JSON"
        
        # Deploy using SSM with properly formatted JSON parameter and retries
        MAX_ATTEMPTS=3
        CURRENT_ATTEMPT=1
        
        while [ $CURRENT_ATTEMPT -le $MAX_ATTEMPTS ]; do
          echo "Attempt $CURRENT_ATTEMPT to send SSM command to instance ${{ env.APP_INSTANCE_ID }}"
          
          if SSM_OUTPUT=$(aws ssm send-command \
            --instance-ids ${{ env.APP_INSTANCE_ID }} \
            --document-name "AWS-RunShellScript" \
            --parameters commands="$COMMANDS_JSON" \
            --query "Command.CommandId" \
            --output text 2>&1); then
              
            echo "SSM command sent successfully! Command ID: $SSM_OUTPUT"
            COMMAND_ID=$SSM_OUTPUT
            
            # Wait for command to complete
            echo "Waiting for SSM command to complete..."
            # Start with shorter waits, then longer ones
            for WAIT_TIME in 10 20 30 60; do
              # Check command status
              STATUS=$(aws ssm list-commands \
                --command-id $COMMAND_ID \
                --query "Commands[0].Status" \
                --output text)
              
              echo "Command status: $STATUS"
              
              if [ "$STATUS" = "Success" ]; then
                echo "✅ SSM command executed successfully!"
                
                # Get command output for logging
                aws ssm get-command-invocation \
                  --command-id $COMMAND_ID \
                  --instance-id ${{ env.APP_INSTANCE_ID }} \
                  --query "StandardOutputContent" \
                  --output text
                
                # Command succeeded, exit the loop
                break 2
              elif [ "$STATUS" = "Failed" ]; then
                echo "❌ SSM command failed, getting error logs:"
                
                # Get error output
                aws ssm get-command-invocation \
                  --command-id $COMMAND_ID \
                  --instance-id ${{ env.APP_INSTANCE_ID }} \
                  --query "StandardErrorContent" \
                  --output text
                
                if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
                  echo "Will retry in 60 seconds..."
                  sleep 60
                  break
                else
                  echo "::error::SSM command failed after $MAX_ATTEMPTS attempts"
                  exit 1
                fi
              elif [ "$STATUS" = "Cancelled" ] || [ "$STATUS" = "TimedOut" ]; then
                echo "⚠️ SSM command $STATUS"
                if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
                  echo "Will retry in 60 seconds..."
                  sleep 60
                  break
                else
                  echo "::error::SSM command $STATUS after $MAX_ATTEMPTS attempts"
                  exit 1
                fi
              else
                echo "Command still in progress, waiting $WAIT_TIME seconds..."
                sleep $WAIT_TIME
              fi
            done
          else
            # Command send failed
            echo "Failed to send SSM command: $SSM_OUTPUT"
            
            if [ $CURRENT_ATTEMPT -lt $MAX_ATTEMPTS ]; then
              echo "Will retry in 60 seconds..."
              sleep 60
            else
              echo "::error::Failed to send SSM command after $MAX_ATTEMPTS attempts"
              exit 1
            fi
          fi
          
          CURRENT_ATTEMPT=$((CURRENT_ATTEMPT + 1))
        done

    - name: Deploy Cortex XDR Agent
      continue-on-error: true
      run: |
        echo "Checking for xdr_install directory and tar.gz file..."
        
        # Debug workspace structure
        echo "Current directory: $(pwd)"
        echo "Listing workspace root content:"
        ls -la
        
        # Initialize error status flag
        XDR_INSTALL_SUCCESS=true
        
        # Check if xdr_install directory exists
        if [ -d "xdr_install" ]; then
          echo "Found xdr_install directory"
          echo "Listing xdr_install content:"
          ls -la xdr_install
          
          # Check for .tar.gz files
          TAR_FILES=$(find xdr_install -name "*.tar.gz" | head -1)
          
          if [ -n "$TAR_FILES" ]; then
            echo "Found tar.gz file: $TAR_FILES"
            
            # Upload the tar.gz file to S3 temporarily for transfer to EC2
            S3_BUCKET="${{ env.TF_STATE_BUCKET }}"
            TAR_FILENAME=$(basename "$TAR_FILES")
            
            # Debug the S3 bucket name
            echo "S3 Bucket: $S3_BUCKET"
            
            # Fallback if TF_STATE_BUCKET is not set
            if [ -z "$S3_BUCKET" ]; then
              echo "TF_STATE_BUCKET not set, falling back to environment value"
              # Get the bucket name from terraform output
              cd terraform
              S3_BUCKET=$(terraform output -raw tf_state_bucket || echo "")
              cd ..
              
              if [ -z "$S3_BUCKET" ]; then
                echo "::warning::Could not determine S3 bucket name for file transfer. XDR installation skipped."
                echo "::notice::XDR Agent installation failed: Could not determine S3 bucket name"
                XDR_INSTALL_SUCCESS=false
              fi
            fi
            
            if [ "$XDR_INSTALL_SUCCESS" = true ]; then
              echo "Using S3 bucket: $S3_BUCKET for XDR installation files"
              
              echo "Uploading $TAR_FILENAME to S3 bucket $S3_BUCKET..."
              aws s3 cp "$TAR_FILES" "s3://$S3_BUCKET/$TAR_FILENAME" || {
                echo "::warning::Failed to upload XDR installation files to S3. XDR installation skipped."
                echo "::notice::XDR Agent installation failed: S3 upload error"
                XDR_INSTALL_SUCCESS=false
              }
              
              if [ "$XDR_INSTALL_SUCCESS" = true ]; then
                # Create a script to handle the XDR installation on the EC2 instance
                echo "Creating XDR installation script..."
                
                # Write script contents line by line to avoid heredoc YAML issues
                echo '#!/bin/bash' > xdr_install.sh
                echo '# Exit on command errors but allow the script to continue' >> xdr_install.sh
                echo 'set +e' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create the log directory if it doesn'"'"'t exist' >> xdr_install.sh
                echo 'mkdir -p /var/log' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Log file for installation' >> xdr_install.sh
                echo 'LOG_FILE="/var/log/xdr_install.log"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo 'yum install selinux-policy-devel.noarch -y' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Function for logging' >> xdr_install.sh
                echo 'log() {' >> xdr_install.sh
                echo '  echo "[$(date '"'"'+%Y-%m-%d %H:%M:%S'"'"')] $1" | tee -a "$LOG_FILE"' >> xdr_install.sh
                echo '}' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Start installation process' >> xdr_install.sh
                echo 'log "Starting Cortex XDR installation"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create temporary directory for download' >> xdr_install.sh
                echo 'TEMP_DIR=$(mktemp -d)' >> xdr_install.sh
                echo 'cd "$TEMP_DIR"' >> xdr_install.sh
                echo 'log "Working in temporary directory: $TEMP_DIR"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Download the tar.gz file from S3' >> xdr_install.sh
                echo 'S3_FILE="$1"' >> xdr_install.sh
                echo 'FILENAME=$(basename "$S3_FILE")' >> xdr_install.sh
                echo 'log "Downloading $S3_FILE from S3"' >> xdr_install.sh
                echo 'aws s3 cp "s3://$S3_FILE" .' >> xdr_install.sh
                echo 'if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '  log "ERROR: Failed to download file from S3"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Extract the archive' >> xdr_install.sh
                echo 'log "Extracting $FILENAME"' >> xdr_install.sh
                echo 'tar -xzf "$FILENAME"' >> xdr_install.sh
                echo 'if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '  log "ERROR: Failed to extract archive"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo 'log "Archive extracted successfully"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Create the /etc/panw directory if it doesn'"'"'t exist' >> xdr_install.sh
                echo 'if [ ! -d "/etc/panw" ]; then' >> xdr_install.sh
                echo '  log "Creating /etc/panw directory"' >> xdr_install.sh
                echo '  mkdir -p /etc/panw' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to create /etc/panw directory"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Find the cortex.conf file' >> xdr_install.sh
                echo 'CONF_FILE=$(find . -name "cortex.conf" | head -1)' >> xdr_install.sh
                echo 'if [ -n "$CONF_FILE" ]; then' >> xdr_install.sh
                echo '  log "Found configuration file: $CONF_FILE"' >> xdr_install.sh
                echo '  log "Copying $CONF_FILE to /etc/panw/"' >> xdr_install.sh
                echo '  cp "$CONF_FILE" /etc/panw/' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to copy configuration file"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'else' >> xdr_install.sh
                echo '  log "ERROR: Could not find cortex.conf file"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Find the installation script (cortex*sh)' >> xdr_install.sh
                echo 'INSTALL_SCRIPT=$(find . -name "cortex*sh" | head -1)' >> xdr_install.sh
                echo 'if [ -n "$INSTALL_SCRIPT" ]; then' >> xdr_install.sh
                echo '  log "Found installation script: $INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  log "Setting executable permissions on $INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  chmod +x "$INSTALL_SCRIPT"' >> xdr_install.sh
                echo '  if [ $? -ne 0 ]; then' >> xdr_install.sh
                echo '    log "ERROR: Failed to set executable permissions"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo '  ' >> xdr_install.sh
                echo '  log "Executing installation script"' >> xdr_install.sh
                echo '  ./$INSTALL_SCRIPT' >> xdr_install.sh
                echo '  INSTALL_RESULT=$?' >> xdr_install.sh
                echo '  if [ $INSTALL_RESULT -eq 0 ]; then' >> xdr_install.sh
                echo '    log "Installation completed successfully"' >> xdr_install.sh
                echo '  else' >> xdr_install.sh
                echo '    log "ERROR: Installation failed with exit code $INSTALL_RESULT"' >> xdr_install.sh
                echo '    exit 1' >> xdr_install.sh
                echo '  fi' >> xdr_install.sh
                echo 'else' >> xdr_install.sh
                echo '  log "ERROR: Could not find installation script (cortex*sh)"' >> xdr_install.sh
                echo '  exit 1' >> xdr_install.sh
                echo 'fi' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo '# Clean up' >> xdr_install.sh
                echo 'log "Cleaning up temporary directory"' >> xdr_install.sh
                echo 'cd /' >> xdr_install.sh
                echo 'rm -rf "$TEMP_DIR"' >> xdr_install.sh
                echo '' >> xdr_install.sh
                echo 'log "Cortex XDR installation process completed"' >> xdr_install.sh
                echo 'exit 0' >> xdr_install.sh
                
                # Make the script executable
                chmod +x xdr_install.sh
                
                # Upload the script to S3
                aws s3 cp xdr_install.sh "s3://$S3_BUCKET/xdr_install.sh" || {
                  echo "::warning::Failed to upload XDR installation script to S3. XDR installation skipped."
                  echo "::notice::XDR Agent installation failed: Script upload error"
                  XDR_INSTALL_SUCCESS=false
                }
                
                if [ "$XDR_INSTALL_SUCCESS" = true ]; then
                  # Get both instance IDs using AWS CLI instead of Terraform
                  echo "Getting instance IDs using AWS CLI..."
                  
                  # Get App Instance ID (already available from env variable)
                  APP_INSTANCE_ID="${{ env.APP_INSTANCE_ID }}"
                  
                  # Get Jenkins Instance ID directly from AWS using tags
                  JENKINS_INSTANCE_ID=$(aws ec2 describe-instances \
                    --filters "Name=tag:Name,Values=${{ env.PROJECT_NAME }}-jenkins-instance" "Name=instance-state-name,Values=pending,running" \
                    --query "Reservations[*].Instances[*].[InstanceId]" \
                    --output text | head -n1)
                  
                  echo "App Instance ID: $APP_INSTANCE_ID"
                  echo "Jenkins Instance ID: $JENKINS_INSTANCE_ID"
                  
                  # Install XDR on both instances
                  for INSTANCE_ID in "$APP_INSTANCE_ID" "$JENKINS_INSTANCE_ID"; do
                    # Skip if instance ID is empty
                    if [ -z "$INSTANCE_ID" ]; then
                      echo "::warning::Empty instance ID, skipping XDR installation for this instance"
                      continue
                    fi
                    
                    echo "Running XDR installation on instance $INSTANCE_ID..."

                    # Create the SSM command to download and run the installation script
                    XDR_COMMANDS='["aws s3 cp s3://'$S3_BUCKET'/xdr_install.sh /tmp/xdr_install.sh", "chmod +x /tmp/xdr_install.sh", "/tmp/xdr_install.sh '$S3_BUCKET'/'$TAR_FILENAME'"]'
                    
                    # Execute the installation via SSM
                    echo "Sending SSM command to instance $INSTANCE_ID..."
                    aws ssm send-command \
                      --instance-ids "$INSTANCE_ID" \
                      --document-name "AWS-RunShellScript" \
                      --parameters commands="$XDR_COMMANDS" \
                      --query "Command.CommandId" \
                      --output text > "ssm_command_id_${INSTANCE_ID}.txt" || {
                        echo "::warning::Failed to send SSM command to instance $INSTANCE_ID. XDR installation skipped."
                        echo "::notice::XDR Agent installation failed on instance $INSTANCE_ID: SSM command error"
                        continue
                      }
                    
                    # Get the command ID directly from output file
                    SSM_COMMAND_ID=$(cat "ssm_command_id_${INSTANCE_ID}.txt")
                    echo "Instance $INSTANCE_ID - SSM Command ID: $SSM_COMMAND_ID"
                    
                    # If the command ID is empty or invalid, the installation will be skipped
                    if [ -z "$SSM_COMMAND_ID" ] || [ ${#SSM_COMMAND_ID} -lt 36 ]; then
                      echo "::warning::Failed to get valid SSM Command ID for instance $INSTANCE_ID. XDR installation status unknown."
                      echo "::notice::XDR Agent installation failed on instance $INSTANCE_ID: Could not get valid command ID"
                    else
                      # Wait for the command to complete
                      echo "Waiting for the XDR installation to complete on instance $INSTANCE_ID..."
                      
                      # Initialize variables
                      SSM_STATUS="Pending"
                      MAX_RETRIES=7
                      COUNT=0
                      
                      # Loop until the command completes or times out
                      while [ "$SSM_STATUS" != "Success" ] && [ "$SSM_STATUS" != "Failed" ] && [ "$COUNT" -lt "$MAX_RETRIES" ]; do
                        # Get the command status
                        SSM_STATUS=$(aws ssm list-commands \
                          --command-id "$SSM_COMMAND_ID" \
                          --query "Commands[0].Status" \
                          --output text)
                        
                        echo "Instance $INSTANCE_ID - Attempt $COUNT/$MAX_RETRIES: Command status is $SSM_STATUS"
                        
                        if [ "$SSM_STATUS" == "Success" ]; then
                          echo "✅ XDR installation on instance $INSTANCE_ID completed successfully."
                          break
                        elif [ "$SSM_STATUS" == "Failed" ]; then
                          echo "⚠️ XDR installation on instance $INSTANCE_ID encountered an issue. See logs for details."
                          echo "::warning::XDR installation failed on instance $INSTANCE_ID."
                          echo "::notice::XDR Agent installation failed on instance $INSTANCE_ID: Installation script error"
                          # Get the command output to understand the failure
                          aws ssm get-command-invocation \
                            --command-id "$SSM_COMMAND_ID" \
                            --instance-id "$INSTANCE_ID" \
                            --query "StandardOutputContent" \
                            --output text
                          aws ssm get-command-invocation \
                            --command-id "$SSM_COMMAND_ID" \
                            --instance-id "$INSTANCE_ID" \
                            --query "StandardErrorContent" \
                            --output text
                          break
                        fi
                        
                        # Increment counter and wait before checking again
                        COUNT=$((COUNT+1))
                        sleep 10
                      done
                      
                      if [ "$COUNT" -ge "$MAX_RETRIES" ]; then
                        echo "⚠️ Timed out waiting for XDR installation on instance $INSTANCE_ID to complete. Current status: $SSM_STATUS"
                        echo "::warning::Timed out waiting for XDR installation on instance $INSTANCE_ID to complete."
                        echo "::notice::XDR Agent installation status on instance $INSTANCE_ID: Timeout - final status unknown"
                      fi
                    fi
                  done
                fi
              fi
            fi
          else
            echo "⚠️ No .tar.gz files found in xdr_install directory."
            echo "::notice::XDR Agent installation skipped: No .tar.gz files found"
            XDR_INSTALL_SUCCESS=false
          fi
        else
          echo "⚠️ xdr_install directory not found in the repository."
          echo "::notice::XDR Agent installation skipped: Directory not found"
          XDR_INSTALL_SUCCESS=false
        fi
        
        # Final installation status summary
        if [ "$XDR_INSTALL_SUCCESS" = true ]; then
          echo "::notice::Cortex XDR Agent installation completed successfully"
        else
          echo "::warning::Cortex XDR Agent installation did not complete successfully, but build will continue"
        fi

    - name: Output Deployment Info
      run: |
        echo "Application deployed successfully!"
        
        if [ -n "${{ env.APP_ALB_URL }}" ]; then
          echo "Application Load Balancer URL: ${{ env.APP_ALB_URL }}"
          echo "::notice title=✅ Application URL::${{ env.APP_ALB_URL }}"
        else
          echo "Application Load Balancer URL: Not available"
        fi
        
        if [ -n "${{ env.ALB_DNS_NAME }}" ]; then
          echo "Application Load Balancer DNS: ${{ env.ALB_DNS_NAME }}"
        else
          echo "Application Load Balancer DNS: Not available"
        fi
        
        EC2_IP=$(aws ec2 describe-instances --instance-ids ${{ env.APP_INSTANCE_ID }} --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null)
        if [ -n "$EC2_IP" ] && [ "$EC2_IP" != "None" ]; then
          echo "Direct EC2 URL: http://$EC2_IP:80"
          echo "::notice title=🔗 Direct EC2 Access::http://$EC2_IP:80"
        else
          echo "Direct EC2 URL: Not available"
        fi
        
        JENKINS_IP=$(aws ec2 describe-instances --filters 'Name=tag:Name,Values=${{ env.PROJECT_NAME }}-jenkins-instance' --query 'Reservations[0].Instances[0].PublicIpAddress' --output text 2>/dev/null)
        if [ -n "$JENKINS_IP" ] && [ "$JENKINS_IP" != "None" ]; then
          echo "Jenkins server should be accessible at: http://$JENKINS_IP:8080"
          echo "::notice title=🛠️ Jenkins Server::http://$JENKINS_IP:8080 (username: admin, password: admin123)"
        else
          echo "Jenkins server: Not available or still starting up"
        fi
        
        # Add a summary of all deployment URLs in Markdown format
        echo "## 🚀 Deployment URLs" >> $GITHUB_STEP_SUMMARY
        
        if [ -n "${{ env.APP_ALB_URL }}" ]; then
          echo "* **Application (ALB)**: [${{ env.APP_ALB_URL }}](${{ env.APP_ALB_URL }})" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -n "$EC2_IP" ] && [ "$EC2_IP" != "None" ]; then
          echo "* **Application (Direct EC2)**: [http://$EC2_IP:80](http://$EC2_IP:80)" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -n "$JENKINS_IP" ] && [ "$JENKINS_IP" != "None" ]; then
          echo "* **Jenkins Server**: [http://$JENKINS_IP:8080](http://$JENKINS_IP:8080)" >> $GITHUB_STEP_SUMMARY
          echo "  * Username: `admin`" >> $GITHUB_STEP_SUMMARY
          echo "  * Password: `admin123`" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "* **Terraform State Bucket**: \`${{ env.TF_STATE_BUCKET }}\`" >> $GITHUB_STEP_SUMMARY
        
        echo "Terraform state is stored in S3 bucket: ${{ env.TF_STATE_BUCKET }}"
        echo "To destroy this infrastructure, use the Destroy Infrastructure workflow with this bucket name." 